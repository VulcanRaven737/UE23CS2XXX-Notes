# â˜ï¸ Cloud Computing: Complete Study Notebook

### Topics: Containers Â· Namespaces Â· cgroups Â· Docker Â· UnionFS Â· DevOps Â· Kubernetes

---

> **How to use this notebook:** Each major topic is explained in depth, followed by a dedicated Q&A section to test and reinforce your understanding. Read through once, then use the Q&A as flashcards.

---

# PART 1 â€” CONTAINERS & LIGHTWEIGHT VIRTUALIZATION

---

## 1.1 Motivation: Why Do We Need Containers?

Before containers, we had **Virtual Machines (VMs)**. VMs virtualize the hardware itself â€” each VM runs a complete, separate OS on top of a hypervisor. This provides strong isolation but comes with a heavy cost:

- Each VM carries a **full OS image** (gigabytes of storage).
- VMs take **minutes to boot** because the OS must initialize completely.
- I/O performance suffers due to the extra abstraction layers.
- Running 10 different applications means 10 separate OS instances, each needing its own patches, updates, and security fixes.

Traditional operating systems _do_ support multiple application processes, but all of them **share the same disk and filesystem** â€” any process (with enough permission) can see the entire filesystem. Isolation is only provided by access-control rules, not structural separation.

**The core problem:** We want isolation (so one app can't break another), but we don't want the massive overhead of a full VM. We need something that:

1. Is lightweight (starts in seconds, uses megabytes, not gigabytes)
2. Provides genuine isolation (separate filesystem view, separate network, separate process space)
3. Shares the underlying OS kernel (no need to boot a new OS for each app)

**Containers** solve this problem precisely.

---

## 1.2 What is a Container?

A **container** is an isolated, lightweight runtime environment for running an application. It uses features built directly into the Linux kernel â€” specifically **namespaces** and **cgroups** â€” to create the illusion of a completely separate system for each application, without actually running a separate OS.

Key definition from Linux Containers (LXC):

> **LXC (Linux Containers)** is an OS-level virtualization method for running multiple isolated Linux systems (containers) on a single Linux host, without creating full-fledged virtual machines.

**Container Characteristics:**

- Containers sit on top of the **physical server and its host OS**.
- They **share the host OS kernel** and often the binaries/libraries too (as read-only). This means you only need to maintain and patch one OS for the host.
- They are **only megabytes in size** vs gigabytes for a VM.
- They start in **seconds** vs minutes for a VM (creation is similar to process creation).
- They offer **speed, agility, and portability**.
- Provisioning performance is much higher than VMs.

**Memory model:**

- The OS kernel runs in **kernel space**.
- User applications run in **user space**.
- Programs in user space cannot directly modify kernel space memory.
- Containers are child processes of the container engine (e.g., Docker daemon), each wrapped in an isolated user space subspace.

---

## 1.3 Containers vs Virtual Machines â€” A Deep Comparison

|Feature|Virtual Machine|Container|
|---|---|---|
|**OS**|Full separate OS per VM|Shares host OS kernel|
|**Size**|Gigabytes|Megabytes|
|**Startup time**|Minutes|Seconds|
|**Isolation**|Hardware-level (strong)|OS-level (lighter)|
|**Performance**|Lower (I/O overhead, boot overhead)|Higher (process-like creation)|
|**Flexibility**|Can run different OS types (Windows, Linux, etc.)|Must match host OS kernel type|
|**Resource usage**|More (each VM has its own OS)|Less (shared kernel)|
|**Management overhead**|High (patch each VM's OS separately)|Low (one host OS to maintain)|
|**Portability**|Moderate (large images)|High (small, fast-moving images)|

**Analogy:** A VM is like building a separate house for each tenant. A container is like giving each tenant their own locked room in a shared building â€” they can't access each other's rooms, but they share the building's plumbing and electricity (the kernel).

---

## ðŸ“ Q&A â€” Containers & Motivation

**Q1. What is the primary motivation for using containers over VMs?**

> Containers provide process-level isolation with dramatically lower overhead. They share the host OS kernel (saving gigabytes and minutes of boot time), start in seconds, use only megabytes of storage, and require maintaining only one OS instead of one per application.

**Q2. What is LXC?**

> LXC (Linux Containers) is an OS-level virtualization method that runs multiple isolated Linux systems on a single host using a single Linux OS instance. It uses Linux kernel features â€” cgroups and namespace isolation â€” to achieve this without creating full virtual machines.

**Q3. How does container creation compare to process creation?**

> Container creation is essentially similar to process creation in terms of speed and mechanism. This is why containers start in seconds whereas VMs take minutes â€” VMs must boot an entire OS, while containers just spin up a new isolated process group.

**Q4. What does "containers share the host OS kernel" mean practically?**

> Practically, it means all containers running on a host use the _same_ Linux kernel. The kernel code, loaded drivers, and core OS services are shared. Each container only gets its own isolated view of userspace resources (files, processes, network), not a separate kernel. This is why you can't run a Windows container on a Linux host kernel.

**Q5. Why do containers have "higher provisioning performance"?**

> Because their creation mirrors process creation â€” the OS doesn't need to boot, load drivers, or initialize an OS from scratch. The kernel is already running; Docker simply sets up namespaces and cgroups and spawns the container process. This makes containers ideal for auto-scaling scenarios.

**Q6. True or False: A container on a Linux host can run a macOS-based container.**

> **False.** Containers share the host OS kernel. Since macOS uses a Darwin/XNU kernel (completely different from Linux), you cannot run a native macOS container on a Linux host. The container must be compatible with the host's kernel type.

**Q7. What is the difference between OS-level virtualization and hardware-level virtualization?**

> Hardware-level virtualization (VMs) virtualizes the physical hardware so that each VM thinks it has its own CPU, RAM, and disk â€” allowing completely different OSes to run. OS-level virtualization (containers) virtualizes only the operating system environment â€” processes share the kernel but get isolated views of filesystem, network, and process tables.

---

# PART 2 â€” DOCKER

---

## 2.1 What is Docker?

**Docker** is an open-source platform that makes it easy to create, test, ship, deploy, and run applications using containers. It can be looked at as a **PaaS (Platform as a Service) product** that uses OS-level virtualization to deliver software packages called containers.

Docker:

- **Separates applications from infrastructure**, enabling faster deployment.
- Significantly reduces the time from writing code to running it in production.
- Packages an application and all its dependencies into a **loosely isolated environment called a container**.
- Provides isolation and security, allowing **8â€“18 containers** to run simultaneously on a single server or VM.
- Runs on Linux; also available natively for macOS and Windows.
- Supports network applications (web servers, databases, mail servers), terminal applications (compilers, editors), and even GUI applications.

**Key benefit:** Docker containers include _everything_ needed to run an application â€” runtime, libraries, config files, dependencies â€” so you don't depend on what's installed on the host system. The container runs identically on any machine that has Docker.

---

## 2.2 Docker Architecture

Docker uses a **client-server architecture** with three major components:

### 2.2.1 Docker Daemon (`dockerd`)

- Runs on the Docker Host.
- Listens for Docker API requests.
- Manages Docker **objects**: images, containers, networks, volumes.
- Can communicate with other daemons to manage Docker services.
- Does all the heavy lifting: building, running, distributing containers.

### 2.2.2 Docker Client (`docker`)

- The primary way users interact with Docker (via CLI commands like `docker run`, `docker build`).
- Sends commands to `dockerd` (the daemon) via the **Docker API**.
- Communicates over **UNIX sockets** or a **network interface**.
- Can connect to more than one daemon (local or remote).

### 2.2.3 Docker Host

- The machine running the Docker daemon.
- Can host a **private registry** or connect to a **public registry** (Docker Hub).
- Responsible for managing Docker objects: images and running containers.

### 2.2.4 Docker Registries

- A **Docker registry** stores Docker images.
- **Docker Hub** is the default public registry â€” anyone can push or pull images.
- Organizations can run **private registries** for internal use.
- `docker pull` / `docker run` pulls images from the configured registry.
- `docker push` uploads your image to the registry.

**How communication works:** Docker client â†’ REST API call â†’ Docker daemon â†’ manages containers/images.

---

## 2.3 Docker Objects

### 2.3.1 Images

A Docker **image** is a **read-only template** with instructions for creating a Docker container.

Key properties:

- Can be based on another image with additional customization (e.g., Ubuntu image + web server configuration = custom web server image).
- Built from a **Dockerfile** â€” a script that defines step-by-step instructions to build the image.
- Each instruction in a Dockerfile creates a **layer** in the image.
- **Layers are incremental**: when you rebuild after a change, only changed layers are rebuilt â€” making builds fast and images small.
- Internally, Docker treats each layer like an intermediate image; layers build upon a parent layer by applying filesystem changes.
- Images are stored in registries and can be shared.

**What is a layer?** A layer is a set of files and file metadata packaged and distributed as an atomic unit. Think of each layer as a "snapshot" of filesystem changes at that point in the Dockerfile. This layered system is powered by **UnionFS** (covered in Part 4).

### 2.3.2 Dockerfile

- A text script that defines how to build a Docker image.
- Distributed alongside software (often via Git repos).
- Each line = one instruction = one layer.
- To build: `docker build -t my_image:latest .`
- Common pattern: clone from Git, then build from the included Dockerfile.

### 2.3.3 Containers

A Docker **container** is a **runnable instance of an image** â€” the live, executing application.

Key properties:

- Created from an image plus a temporary **read/write layer** on top (the container layer).
- This writable layer is **deleted when the container is removed** â€” data doesn't persist by default.
- Multiple containers can share the same underlying image, each with their own separate temporary storage.
- Can be started, stopped, moved, deleted via Docker API or CLI.
- Can connect to networks, mount storage volumes, and create new images from their current state.
- Well **isolated** from other containers and the host â€” controlled via namespaces.

### 2.3.4 Volumes

- Used for **persistent data storage** that survives container deletion.
- Volumes solve the problem of the container's writable layer being ephemeral.
- Can be shared between containers.

### 2.3.5 Networks

- Allow containers to communicate with each other and the outside world.
- Docker sets up virtual networks for container communication.

---

## 2.4 How Docker Runs a Program

When you run `docker run <image>`:

1. Docker checks if the image is already local. If not, pulls it from the registry.
2. Creates a new container (a runnable instance of the image).
3. Creates a set of **namespaces** for the container (isolation).
4. Sets up **cgroups** (resource limits).
5. Allocates a read/write filesystem layer on top of the image's read-only layers.
6. Starts the process specified in the image.

Running `docker run` a second time with the same image: Docker already has the image locally, so it creates a new container immediately without downloading anything.

---

## ðŸ“ Q&A â€” Docker

**Q1. What is Docker and how is it different from a VM?**

> Docker is an open platform for containerizing applications. Unlike a VM (which includes a full OS), Docker containers share the host OS kernel, making them much lighter, faster, and more portable. Docker provides OS-level virtualization, while VMs provide hardware-level virtualization.

**Q2. Explain Docker's client-server architecture.**

> Docker uses a client-server model. The Docker **client** (CLI) sends commands to the Docker **daemon** (`dockerd`) via REST API over UNIX sockets or a network interface. The daemon performs the actual work of building, running, and managing containers and images. They can run on the same machine or on separate machines.

**Q3. What is a Dockerfile and what does each instruction do?**

> A Dockerfile is a text script of instructions that define how to build a Docker image. Each instruction (e.g., `FROM`, `RUN`, `COPY`, `EXPOSE`) creates a **new layer** in the resulting image. This layered structure makes images efficient â€” rebuilds only reprocess changed layers.

**Q4. What is the difference between a Docker image and a Docker container?**

> An **image** is a read-only template â€” a static blueprint. A **container** is a running (or stopped) instance of that image â€” a live process with its own writable layer. Multiple containers can be spawned from the same image, each with their own temporary storage.

**Q5. Why does data disappear when a container is deleted?**

> By default, all changes a container makes are written to a temporary **writable layer** that sits on top of the read-only image layers. When the container is removed, this writable layer is discarded. To persist data, you must use **Volumes**, which are separate from the container lifecycle.

**Q6. What is Docker Hub and why is it important?**

> Docker Hub is Docker's default **public registry** â€” a cloud-based library where users and organizations can push and pull Docker images. It's important because it enables sharing, discovery, and distribution of container images globally. Private registries can be self-hosted for organizational use.

**Q7. If you run `docker run ubuntu` twice, how many times does Docker download the Ubuntu image?**

> **Only once.** The first run downloads the image from Docker Hub and caches it locally. The second run finds the image already present and immediately creates a new container without downloading again.

**Q8. What is the Docker daemon and what is its role?**

> The Docker daemon (`dockerd`) is the background service that runs on the Docker Host. It listens for API requests from the Docker client and handles all the heavy lifting: building images, creating and running containers, managing networks and volumes, and communicating with registries. Without the daemon running, no Docker commands work.

---

# PART 3 â€” LINUX NAMESPACES

---

## 3.1 What is a Namespace?

A **namespace** is a Linux kernel feature that **wraps a global system resource in an abstraction** that makes processes within a namespace believe they have their own isolated instance of that resource. Processes in different namespaces see different, distinct resources even though they share the same physical machine.

**Core principle:** If you can't name (see) an object, you can't access it. By controlling what names (and therefore what resources) are visible to a process, you control what it can access.

All the resources that a process can see form its **namespace**:

- Files it can see â†’ **file/mount namespace**
- Network connections it can use â†’ **network namespace**
- Processes it can see â†’ **PID namespace**

Docker uses namespaces to create the **isolated workspace** called a container. When you run a container, Docker creates a set of namespaces for that container, providing a layer of isolation.

---

## 3.2 The Seven Major Docker Namespaces

Docker uses these namespace types to isolate containers:

### 1. PID Namespace (Process ID)

- Gives a container its own isolated process tree.
- Processes inside the container are **not aware** of processes outside their namespace.
- The first process in a new PID namespace gets PID 1 (like `init` on a normal system).
- From outside the container, you can see all PIDs, but the container only sees its own.

### 2. UTS Namespace (Unix Time Sharing)

- Isolates **hostname** and **NIS domain name**.
- Each container can have its own hostname and Fully Qualified Domain Name (FQDN).
- Processes inside a namespace can change their UTS values, but changes only affect their own namespace.
- Named after the data structure used by the `uname` system call.
- Why "Unix Time Sharing"? Historical naming from the era of time-shared Unix systems.

### 3. MNT Namespace (Mount)

- Isolates the **filesystem mount points**.
- Processes in different MNT namespaces cannot view each other's files (similar to `chroot`).
- Container 1 sees `/mnt` but not `/mnt2`. Container 2 sees `/mnt2` but not `/mnt`. Both can see shared `/usr`.
- Created with `clone(CLONE_NEWNS)` system call.

**Before namespaces:** All processes share one global filesystem rooted at `/`. All can see `/bin`, `/usr`, `/mnt`, etc.

**After namespaces:** Each container gets its own isolated view â€” Container 1 might see a completely different `/` than Container 2, even though they're on the same physical machine.

### 4. NET Namespace (Network)

- Creates a **virtual network barrier** around a process.
- Each namespace has its own: network interfaces (ethernets), IP addresses, routing tables, port ranges, firewall rules.
- Completely isolates network connectivity in and out.
- A process in the NET namespace can have its own IP address, full range of ports (0â€“65535), and routing rules.

**VETH (Virtual Ethernet) devices:**

- Used when namespaces need to communicate with the host or each other.
- Created in **pairs** â€” like two ends of a pipe.
- Packets sent on one device are immediately received on the other.
- When either device is down, the link state of the pair is also down.

### 5. IPC Namespace (Inter-Process Communication)

- Isolates **shared memory** communication between processes.
- Prevents containers from accessing each other's shared memory segments, message queues, and semaphores.
- Provides isolation for process communication over shared memory.

### 6. USR Namespace (User)

- Provides **user name and UID mapping** â€” a process can appear to run as root inside a namespace but be a non-privileged user from the host's perspective.
- Isolates changes in user names/metadata within a container.

### 7. chroot (change root)

- Technically a **system call**, not a namespace, but used by Docker for filesystem isolation.
- Changes the **root directory** (`/`) for currently running processes and their children.
- Example: `chroot /mnt command` â€” `command` will see `/mnt` as its root, not the real `/`.
- Using chroot, every process can be given its own filesystem.
- **Limitation:** chroot can be escaped by a process with sufficient capabilities.
- **Better alternative:** `pivot_root` â€” detaches the new root and attaches it to the process root directory. Used when building system images.

### Also used: cgroups and CAP drop

- **cgroups** â€” for resource accounting and limiting (detailed in Part 4).
- **CAP drop** â€” drops OS capabilities to restrict what the container process can do.
- **Security modules** â€” mandatory access controls (e.g., AppArmor, SELinux).

---

## 3.3 Namespace System Calls

Creating and managing namespaces involves three main system calls:

- **`clone()`** â€” Creates a new child process (like `fork()`). Flags like `CLONE_NEWNS` specify which new namespaces to create. `pid = clone(childFunc, stackTop, CLONE_NEWNS | SIGCHLD, argv[1])` â€” this creates a process with a new mount namespace.
- **`setns(int fd, int nstype)`** â€” Allows a process to **join an existing namespace**. `fd` is a file descriptor to the namespace (from `/proc/pid/ns/`), `nstype` specifies the namespace type.
- **`unshare(int flags)`** â€” Allows a process to create a **new namespace for itself** without creating a new process. `CLONE_NEWNS` creates a new mount namespace for the caller.

**Inspecting namespaces:** Each process's namespace memberships are visible at `/proc/[pid]/ns/`. For example: `ls -l /proc/pidx/mnt` might show `mnt -> mnt:[4026531840]` â€” the number is the namespace ID.

---

## ðŸ“ Q&A â€” Linux Namespaces

**Q1. What is a Linux namespace in simple terms?**

> A namespace wraps a global system resource so that each group of processes has its own isolated instance of that resource. Processes inside a namespace believe they have exclusive access to that resource, even though they share the same physical kernel. Docker uses namespaces to create the isolation that makes containers work.

**Q2. What does the PID namespace isolate?**

> The PID namespace isolates the process ID space. Processes inside a container's PID namespace can only see their own processes (with their own PID numbering starting from 1). They cannot see or signal processes in other containers or on the host. This prevents one container from affecting another's processes.

**Q3. Why does each Docker container need a UTS namespace?**

> Each container needs its own hostname to be independently identifiable on a network and to avoid confusion when logs or applications reference the machine's hostname. The UTS namespace gives each container its own hostname and domain name, isolated from the host and other containers.

**Q4. What is the MNT namespace and how does it provide filesystem isolation?**

> The MNT (mount) namespace isolates the set of filesystem mount points visible to a group of processes. Container 1 can only see its own mounted filesystems (e.g., `/mnt`) while Container 2 sees its own (e.g., `/mnt2`). They cannot access each other's filesystems. Both may still share read-only shared directories like `/usr`.

**Q5. Explain VETH devices and why they are needed.**

> VETH (Virtual Ethernet) devices are pairs of virtual network interfaces that act like a pipe. Since the NET namespace isolates each container's network stack, containers by default cannot communicate. A VETH pair bridges two NET namespaces â€” packets sent on one end are instantly received on the other. One end lives in the container's namespace, the other in the host's, enabling communication.

**Q6. What is chroot and why is pivot_root preferred?**

> `chroot` changes the root directory for a process and its children, giving each process its own apparent filesystem root. However, a process with sufficient capabilities can **escape chroot** by navigating to a directory that references the real root. `pivot_root` is more secure â€” it completely detaches the new root from the old one and attaches it to the process's root directory, preventing escape.

**Q7. What is the difference between `clone()`, `setns()`, and `unshare()`?**

> - `clone()` creates a _new process_ with new namespaces (specified by flags like `CLONE_NEWNS`).
> - `setns()` lets an _existing process join_ an already-existing namespace (useful for tools that attach to a running container's namespace).
> - `unshare()` lets the _current process create_ a new namespace for itself without spawning a new process.

**Q8. How can you identify which mount namespace a process belongs to?**

> By checking `/proc/[pid]/ns/mnt`. Running `ls -l /proc/[pid]/ns/mnt` shows a symlink like `mnt -> mnt:[4026531840]`. The number in brackets is the namespace ID. Two processes with the same namespace ID share the same mount namespace.

**Q9. What are the 7 isolation features Docker uses to build containers?**

> PID namespace (process isolation), UTS namespace (hostname isolation), MNT namespace (filesystem isolation), NET namespace (network isolation), IPC namespace (shared memory isolation), USR namespace (user ID mapping), and chroot/pivot_root (filesystem root isolation). Plus cgroups for resource limiting and CAP drop for capability restriction.

---

# PART 4 â€” CGROUPS (CONTROL GROUPS)

---

## 4.1 What are cgroups?

**cgroups (Control Groups)** is a Linux kernel feature that **limits, polices, and accounts for the resource usage** of a set of processes. Docker uses cgroups to control and limit system resources available to each container.

> cgroups provides mechanisms to **allocate, monitor, and limit resources** â€” such as CPU time, system memory, block I/O (disk bandwidth), network bandwidth, or combinations of these â€” among user-defined groups of tasks (processes) running on a system.

**Why cgroups matter for containers:** Namespaces give containers isolation (each container thinks it's alone). But without cgroups, a single container could consume _all_ CPU or memory on the host, starving other containers. cgroups solve the "noisy neighbor" problem by enforcing resource limits.

When Docker is installed on Linux, it installs cgroup-related packages and creates subsystem directories.

---

## 4.2 cgroups Functionality

cgroups provides six key functions:

|Function|Description|
|---|---|
|**Access control**|Specifies which devices a cgroup can use|
|**Resource limiting**|Hard limits on memory, CPU, block I/O, etc.|
|**Prioritization**|Which cgroups get more CPU/memory when resources are contested|
|**Accounting**|Tracks resource usage per cgroup (useful for billing, monitoring)|
|**Control**|Freeze and checkpoint cgroup processes|
|**Injection**|Packet tagging for network QoS|

---

## 4.3 What Resources Can cgroups Limit?

All of the following can be limited per cgroup:

- **Memory** â€” maximum RAM a container can use
- **CPU** â€” how much CPU time a container gets (e.g., 50% of one core)
- **Block I/O** â€” disk read/write bandwidth
- **Devices** â€” which hardware devices a container can access and create
- **Network** â€” bandwidth throttling and packet tagging

---

## 4.4 cgroups Structure and Hierarchy

- cgroups are **hierarchically structured** â€” each group is created for a resource with an associated number.
- **Tasks (processes) are assigned to cgroups.**
- Each cgroup has a **resource limitation** associated with it.
- There is a **separate hierarchy for each resource type** (one for memory, one for CPU, etc.).
- **Inheritance:** When a process creates a child process, the child stays in the **same cgroup** as the parent. This means resource limits automatically apply to all forked child processes. This is extremely useful for servers (like NFS) that fork children to handle requests â€” all children share the parent's resource budget.

**Example workflow of inheritance:**

1. Server process is in a cgroup with 500MB memory limit.
2. Server receives a request and forks a child process.
3. Child process inherits the cgroup and is bound by the same 500MB limit.
4. When the child terminates, its resources are freed back.

---

## 4.5 Docker and cgroups in Practice

Docker exposes cgroup controls through `docker run` flags:

```bash
# Limit container to 50% of one CPU core
docker run -d --name mycontainer --cpus="0.5" ubuntu sleep 1000

# Limit container memory to 100 megabytes
docker run -d --name mycontainer --memory=100m ubuntu sleep 1000

# Verify the CPU quota set in the cgroup
docker exec mycontainer cat /sys/fs/cgroup/cpu/cpu.cfs_quota_us

# Verify the memory limit set in the cgroup
docker exec mycontainer cat /sys/fs/cgroup/memory/memory.limit_in_bytes

# Live stats monitoring
docker stats mycontainer
```

**OOM (Out of Memory) Killer example:**

```bash
docker run -d --name mem_test --memory=100m ubuntu sleep 1000
docker exec -it mem_test stress --vm 1 --vm-bytes 150m --timeout 30s
# Container should be killed by the OOM killer
docker logs mem_test
docker ps -a | grep mem_test   # Shows: Exited (137) â€” killed due to OOM
```

Exit code **137** means the process was killed by signal 9 (SIGKILL), used by the OOM killer.

---

## ðŸ“ Q&A â€” cgroups

**Q1. What is the difference between namespaces and cgroups?**

> **Namespaces** provide **isolation** â€” they control _what_ a container can see (files, processes, network, etc.). **cgroups** provide **resource control** â€” they control _how much_ of the host's resources a container can consume (CPU, memory, I/O). Together, they are the two foundational pillars of container technology.

**Q2. What problem do cgroups solve?**

> The "noisy neighbor" problem. Without cgroups, a single container could consume 100% of CPU or exhaust all available RAM, causing other containers and the host to starve. cgroups enforce hard limits, ensuring fair and predictable resource allocation among all containers.

**Q3. Name the six functions of cgroups.**

> 1. Access control (which devices can be used), 2. Resource limiting (memory, CPU, I/O limits), 3. Prioritization (who gets more resources under contention), 4. Accounting (tracking usage for billing/monitoring), 5. Control (freezing and checkpointing), 6. Injection (packet tagging).

**Q4. What happens to resource limits when a process forks a child?**

> The child process remains in the **same cgroup** as the parent, inheriting the same resource limits. This is intentional and useful â€” for example, an NFS server that forks child processes to handle requests will have all children count against the server's resource budget.

**Q5. A container exits with code 137. What does this mean?**

> Exit code 137 = 128 + 9, indicating the process was killed by SIGKILL (signal 9). In Docker's context, this typically means the **OOM (Out of Memory) killer** terminated the container because it tried to use more memory than its cgroup limit allowed.

**Q6. How do you limit a Docker container to use only 1 CPU and 512MB RAM?**

> ```bash
> docker run -d --name myapp --cpus="1.0" --memory=512m myimage
> ```

**Q7. Where in the Linux filesystem can you find cgroup settings for a running container?**

> Under `/sys/fs/cgroup/`. For example:
> 
> - CPU quota: `/sys/fs/cgroup/cpu/cpu.cfs_quota_us`
> - Memory limit: `/sys/fs/cgroup/memory/memory.limit_in_bytes` These files can be read from inside the container using `docker exec`.

---

# PART 5 â€” UNION FILESYSTEM (UnionFS)

---

## 5.1 What is a Union Filesystem?

A **Union Filesystem (UnionFS)** is a type of filesystem that creates an **illusion of merging the contents of several directories (created in layers) into one** unified view, **without modifying the original physical sources**.

Key features:

- Creates a **single merged view** of multiple directories layered on top of each other.
- Operates by creating **layers**, making it very lightweight and fast.
- Docker Engine uses UnionFS to provide the building blocks for containers.
- Supported variants: **AUFS, overlay2, btrfs, vfs, DeviceMapper**.

**Simple analogy:** Imagine two transparent sheets. Sheet A has "Apple, Tomato". Sheet B has "Carrots, Tomato". If you stack Sheet A on top of Sheet B and look through both, you see "Apple, Tomato, Carrots" â€” and the "Tomato" you see comes from the top sheet (Sheet A). You haven't changed either original sheet.

---

## 5.2 UnionFS Layering â€” Detailed Example

```
/Fruits   contains: Apple, Tomato
/Vegetables  contains: Carrots, Tomato

mount -t unionfs -o dirs=/Fruits:/Vegetables none /mnt/healthy

Result: /mnt/healthy contains: Apple, Tomato, Carrots
```

- `Tomato` comes from `/Fruits` because it appears first in the `dirs` option â€” **the top layer wins**.
- `/Fruits` is layered **on top of** `/Vegetables`.
- Neither `/Fruits` nor `/Vegetables` is modified.

**Copy-on-Write (CoW):**

- The `-o cow` mount option enables **Copy-on-Write**.
- If a change is made to a file in the merged view, the **original file is NOT modified**.
- Instead, a **new copy of the file is created in a hidden layer** and the change is written there.
- If `/Fruits` is mounted **read-only**, any changes are recorded in a temporary writable layer on top.

---

## 5.3 Docker and UnionFS â€” The Layer Model

Docker uses UnionFS to implement its **image layer system**:

```
Read-Only Image Layers (stacked):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Layer 4: App code         â”‚  â† top image layer
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  Layer 3: Dependencies     â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  Layer 2: Runtime          â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  Layer 1: Base OS (Ubuntu) â”‚  â† bottom image layer
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Read-Write Container Layer (ephemeral):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Container writable layer  â”‚  â† added when container runs
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- Each instruction in a Dockerfile â†’ one new read-only layer.
- A **read-only layer = image layer**.
- The **top read-write layer = container layer** (ephemeral, deleted when container is removed).
- From inside the container, the filesystem looks like one unified filesystem â€” it doesn't know about the underlying layers.
- Multiple containers can share the same image layers (they all see the same read-only base), each with their own unique writable layer on top.

**Incremental rebuilds:** When a Dockerfile changes and an image is rebuilt, only the layers _after the changed instruction_ need to be rebuilt. Earlier unchanged layers are reused from cache. This makes builds very fast.

---

## 5.4 The Other Tools: MNT Namespace and chroot

UnionFS alone doesn't complete filesystem isolation. The full isolation stack is:

1. **UnionFS** â€” merges layers into a coherent view
2. **MNT namespace** â€” controls which mount points a process can see
3. **chroot/pivot_root** â€” changes what the process considers the root `/` of the filesystem

Together, these three ensure a container sees exactly and only its own filesystem.

---

## 5.5 Weaknesses of UnionFS

UnionFS is powerful but has limitations:

- **Different filesystem rules:** Different underlying filesystems have different rules about file names, attributes, sizes. UnionFS must translate between them, sometimes losing features.
- **Copy-on-Write makes mmap hard:** UnionFS uses CoW, which makes implementing **memory-mapped files** (`mmap` system call) difficult.
- **Not for long-lived data:** The union filesystem is inappropriate for working with long-lived data or sharing data between containers or between a container and the host. Use **volumes** for that.
- **Write performance:** Writing through the CoW layer adds overhead. Most write-performance issues can be addressed by using **volumes** (which bypass the union filesystem entirely).

---

## ðŸ“ Q&A â€” Union Filesystem

**Q1. What is a Union Filesystem and why does Docker use it?**

> A Union Filesystem merges multiple directories (layers) into a single coherent view without modifying any of the originals. Docker uses it to implement its layered image system â€” each Dockerfile instruction creates a new layer, and multiple containers can share base layers while having their own writable top layer. This makes images lightweight, shareable, and fast to rebuild.

**Q2. Explain Copy-on-Write (CoW) in the context of Docker.**

> When a container running on top of read-only image layers needs to modify a file, it doesn't modify the original. Instead, the file is first **copied** to the container's writable layer, and then the modification is made there. The original image layer remains untouched. This allows multiple containers to share the same image layers safely.

**Q3. If two containers run from the same image, do they share files?**

> They share the **read-only image layers** â€” the base filesystem is common. But each container has its own **separate writable layer** on top. Changes one container makes are not visible to the other.

**Q4. What happens to a container's writable layer when the container is deleted?**

> It is permanently deleted. Any data written during the container's lifetime that wasn't stored in a Docker volume is lost. This is why containers are considered "ephemeral" and volumes are needed for persistent data.

**Q5. Name four UnionFS variants supported by Docker.**

> AUFS, overlay2, btrfs, vfs, and DeviceMapper. Docker automatically selects the best available option for the host system.

**Q6. Why is UnionFS unsuitable for database storage?**

> Because of CoW overhead (modifying a file requires copying it first), lack of efficient `mmap` support, and the fact that all data is lost when the container is deleted. Databases need high-performance direct writes and persistent storage â€” both of which are better served by Docker **volumes**.

**Q7. What three components work together to provide complete container filesystem isolation?**

> 1. **UnionFS** â€” merges image layers into one coherent filesystem view.
> 2. **MNT namespace** â€” isolates which mount points the container can see.
> 3. **chroot/pivot_root** â€” sets the container's apparent root directory `/`.

---

# PART 6 â€” DEVOPS

---

## 6.1 What is DevOps?

**DevOps** is a set of practices that **combines and automates the processes** between software development (Dev) and IT operations (Ops) teams so they can build, test, and release software **faster and more reliably**.

Historically, Dev and Ops were **independent specialist teams** with conflicting goals:

- **Dev teams** wanted to ship new features quickly and often.
- **Ops teams** wanted stability, reliability, and predictability â€” resisting frequent changes.

This conflict led to famous frustrations:

- _"Put the current release live, NOW!"_ (Dev)
- _"It works on my machine"_ (Dev)
- _"What are the dependencies?"_ (Ops)
- _"No machines available..."_ (Ops)

DevOps resolves this by automating the pipeline and aligning both teams around shared goals.

**Key facts:**

- DevOps aims to **shorten the SDLC** (Software Development Life Cycle).
- It increases an organization's ability to **deploy and support applications**.
- DevOps is **complementary with Agile** â€” many DevOps concepts come from Agile methodology.
- Docker and Kubernetes are 2 of the 10 most used DevOps tools. Git is another.

---

## 6.2 The DevOps Cycle

DevOps follows a continuous cycle:

```
Plan â†’ Build â†’ Deploy â†’ Operate â†’ (back to Plan)
```

In pre-cloud era: lots of manual intervention was needed (procuring machines, configuring environments, etc.).

In the cloud era: **automation is possible at every stage** â€” machines can be provisioned programmatically, configurations can be version-controlled, deployments can be scripted.

---

## 6.3 Advantages of DevOps

|Advantage|Explanation|
|---|---|
|**Faster Time to Market**|Frequent code check-ins â†’ more builds and tests â†’ features reach customers sooner|
|**Better Code Quality**|Frequent testing catches bugs early; automated tests prevent regressions|
|**Frequent Integration**|Code from different developers/teams is merged often, reducing "integration hell"|
|**Deploy Often**|Changes reach customers frequently, in small increments|
|**Automated**|Pipelines are repeatable and faster than manual processes|
|**Everyone is happy (hopefully!)**|Dev ships features; Ops has stable, well-tested code|

---

## 6.4 Principles of Continuous Delivery

1. **Every build is a potential release** â€” every successful build should be deployable.
2. **Eliminate manual bottlenecks** â€” any manual step in the pipeline is a risk and a delay.
3. **Automate wherever possible** â€” from building to testing to deployment.
4. **Have automated tests you can trust** â€” without trustworthy tests, automation is dangerous.

**Keep it simple:**

- Reduce risk of each release by making **small, incremental changes**.
- Test every cycle.
- Small changes are much easier for both Dev and Ops to reason about.

---

## 6.5 The DevOps Pipeline

A **typical DevOps pipeline** for containerized applications:

```
1. Developer pushes code changes to Git (version control)
          â†“
2. Build system automatically builds the code and runs sanity tests
          â†“
3. If tests pass â†’ container image is published to the central container registry
          â†“
4. Newly built container is automatically deployed to a staging environment
          â†“
5. Staging environment undergoes automated acceptance tests
          â†“
6. Verified container image is deployed to production
```

Every step is **automated** â€” no human needs to approve or manually trigger each stage (though checkpoints can be added).

---

## 6.6 Continuous Development, Integration, Delivery, Testing, and Deployment

### Continuous Development (CD)

- Includes continuous code development, integration, and build.
- Challenges: Developers distributed across geographies, need consistent coding style, must keep changes in sync.
- Solution: Version Control Systems (VCS) like Git ensure everyone has a common view of the code.

### Continuous Integration (CI)

- **Automatic merging** of code changes.
- Requires every module to **compile (build) correctly**.
- Runs **sanity testing** of developers' changes against the mainline branch.
- If your branch would break the build when merged, CI tells you _immediately_ â€” not after weeks of work.
- Tools: **Git, ClearCase, Maven, ANT, Jenkins, Travis CI, Drone**.

### Continuous Delivery

- Frequent shipping of **sanitized (tested) builds** to a given environment (test or production).
- Tool: **Jenkins** (open-source Java-based automation server).

### Continuous Testing

- Executing predominantly **automated tests** as part of the delivery pipeline.
- Goal: validate that the application works as intended and is free of bugs.
- Tests are designed for **minimum wait times** and **earliest possible feedback**.
- Activities:
    - Copy binaries to staging environment.
    - Configure dependencies correctly.
    - Execute test categories: integration tests, functionality tests, performance tests, acceptance tests.
    - Generate reports.
- Tools: **JUnit, Selenium**.

### Continuous Deployment (CD)

- **Automatic deployment of successful builds to production** â€” managed centrally.
- Developers deploy new versions by: pushing a button, merging a merge request, or pushing a Git release tag.
- Requires setting up infrastructure as code.

---

## 6.7 Infrastructure as Code â€” Setting Up the Environment

For Continuous Deployment to work, the environment must be defined in code:

- **Machine types / provisioning:** Chef Provisioning (defines machines and storage)
- **Configuration:** Puppet, Chef Recipes/Cookbooks (define how machines are configured)
- **Container orchestration:** Docker images with scaling policies, load balancers
- **Immutable infrastructure:** Servers are never modified after deployment â€” if something needs updating, new servers are provisioned from a common image, replacing old ones.

**Immutable infrastructure benefits:** More consistency, simpler/more predictable deployments, prevents configuration drift, enables comprehensive deployment automation.

Tools: Chef, Puppet, Kubernetes, Docker.

---

## 6.8 Jenkins

**Jenkins** is the most widely adopted CD (Continuous Delivery/Deployment) tool.

Key facts:

- **Self-contained, open-source automation server** written in Java.
- Automates tasks related to **building, testing, delivering, and deploying software**.
- Can be installed via native packages, Docker, or run standalone on any machine with a JRE (Java Runtime Environment).
- **JenkinsX** is a dedicated side project for running Jenkins in a Kubernetes cluster.
- The Jenkins pipeline (Jenkinsfile) defines the CI/CD workflow as code.

---

## ðŸ“ Q&A â€” DevOps

**Q1. What is DevOps and what problem does it solve?**

> DevOps is a set of practices that automates and integrates the processes between software development and IT operations. It solves the historical conflict between Dev (wanting rapid feature delivery) and Ops (wanting stability) by aligning them through automation, shared tooling, and a continuous pipeline.

**Q2. What is the DevOps cycle and what does each stage mean?**

> **Plan â†’ Build â†’ Deploy â†’ Operate.** Plan: gather requirements. Build: write and compile code. Deploy: release to environments. Operate: monitor and support the running application. With DevOps, this cycle runs continuously and rapidly rather than in slow, large waterfall batches.

**Q3. What is the difference between Continuous Integration, Continuous Delivery, and Continuous Deployment?**

> - **CI (Continuous Integration):** Automatically merge and build code from all developers, running sanity tests on every check-in.
> - **Continuous Delivery:** Frequently shipping tested, verified builds to a given environment (test, staging, or production), but release to production may require a manual trigger.
> - **Continuous Deployment:** Fully automated â€” every passing build is automatically deployed to production with no human intervention.

**Q4. What is "immutable infrastructure" and why does DevOps prefer it?**

> Immutable infrastructure means servers are never modified after deployment. Instead of patching a running server, you provision entirely new servers from an updated, common image. This prevents configuration drift, ensures consistency, makes deployments predictable, and supports full automation.

**Q5. Describe the 6 stages of a typical DevOps pipeline for containerized applications.**

> 1. Developer pushes code to Git. 2. Build system compiles and runs sanity tests. 3. On test pass, container image is published to registry. 4. New container auto-deployed to staging. 5. Automated acceptance tests run on staging. 6. Verified image deployed to production.

**Q6. What is Jenkins and why is it important in DevOps?**

> Jenkins is an open-source automation server that automates the CI/CD pipeline â€” building code, running tests, and deploying applications. It is the most widely used CD tool, supports plugins for almost every tool in the DevOps ecosystem, and can run as a container or standalone on any JRE-equipped machine.

**Q7. What does "every build is a potential release" mean?**

> It means the build pipeline should always produce a deployable artifact. No build should be left in a half-tested, undeployable state. The moment code passes all automated tests, it should be ready (and able) to ship. This principle forces discipline in testing and code quality.

**Q8. Name three tools used for Continuous Testing.**

> JUnit (unit/integration testing for Java), Selenium (browser-based UI testing), and general test runners like pytest, Mocha, etc. In CI/CD pipelines, these tools run automatically on every code push and report failures immediately.

---

# PART 7 â€” CONTAINER ORCHESTRATION & KUBERNETES

---

## 7.1 Why Orchestration?

You've learned to package applications in containers and run them with Docker. But what happens when:

- Your application grows to hundreds of microservices?
- A container crashes â€” who restarts it?
- Traffic spikes â€” who adds more container instances?
- A host server fails â€” who moves containers to healthy servers?
- How do containers discover each other's IP addresses (which change constantly)?

**Container orchestration** is the answer. It automates the **deployment, management, scaling, and networking** of containers across a cluster of machines.

---

## 7.2 Container Orchestration â€” Deep Definition

**Container orchestrator:** A piece of centralized management software that allocates and schedules containers to run on a pool of servers (different machines in a cluster).

**Orchestration vs Scheduling (strict definitions):**

- **Orchestration:** Coordinating and sequencing different activities in service of a common goal (like musicians in an orchestra playing together).
- **Scheduling:** Managing available resources and assigning/deploying workloads where they can most efficiently run.

In practice, the terms are often used interchangeably. The orchestrator handles both.

---

## 7.3 What Does Container Orchestration Do?

Container orchestration controls and automates all of these tasks:

- **Provisioning and deployment** â€” spinning up containers on appropriate hosts
- **Configuration and scheduling** â€” deciding where and when containers run
- **Resource allocation** â€” managing CPU/memory between containers
- **Networking** â€” managing container-to-container communication
- **Availability and redundancy management** â€” keeping the right number of containers running
- **Scaling** â€” adding/removing containers based on load
- **Load balancing and traffic routing** â€” distributing requests across healthy containers
- **Health monitoring** â€” watching container and host health
- **Application configuration** â€” configuring apps based on their container environment
- **Security** â€” keeping interactions between containers secure
- **Migration** â€” moving containers from failing/overloaded hosts to healthy ones

---

## 7.4 Cluster Management and Immutable Infrastructure

**Cluster management** is a key activity of orchestration â€” joining multiple physical or virtual servers into a **unified, reliable, fault-tolerant group** that appears seamless.

Orchestration embraces **immutable infrastructure**:

- Containers are **never modified** after deployment.
- If a fix or update is needed, new containers from an updated image replace old ones.
- Benefits: consistency, reliability, prevents configuration drift, enables full automation.

---

## 7.5 Orchestration Tools

|Tool|Description|
|---|---|
|**Kubernetes (K8s)**|The most pervasive container orchestration platform. Open-source, originally from Google.|
|**Docker Swarm**|Native clustering for Docker, turns multiple Docker engines into a single virtual Docker engine.|
|**Google Container Engine**|Built on Kubernetes, runs Docker containers on Google Cloud.|
|**Amazon ECS**|Amazon's managed container orchestration on EC2 instances.|

---

## 7.6 Kubernetes â€” The Deep Dive

**Kubernetes (K8s)** â€” _K + 8 letters + s_ â€” is the most widely used container orchestration platform.

It is an **open-source container management (orchestration) tool** that handles:

- Container deployment
- Scaling and descaling of containers
- Container load balancing
- Complex application deployments â€” quickly, predictably, reliably.

### 7.6.1 Basic Building Objects

#### 1. Pod

- A **group of one or more containers** that share storage and network within a Kubernetes configuration.
- The **smallest deployable unit** in Kubernetes (not an individual container).
- Pods typically run microservices of an elastic application that communicate with each other.
- **Shared within a pod:** Storage (volumes), Linux namespaces, cgroups, IP address and port space.
- Containers in the same pod communicate via **localhost**.
- Each pod gets its own **IP address** â€” accessible by other pods within the cluster.
- Pods are **ephemeral**: created, destroyed, and re-created on demand based on server and service state.
- Pods are scheduled **only once** to a node and run there until terminated.
- **Self-healing at pod level:** The kubelet can restart containers _inside_ a pod. But if a pod is deleted, it doesn't resurrect itself â€” higher-level controllers (like Deployments) handle that.

**Pod lifecycle:** Pending â†’ Running â†’ Succeeded or Failed.

**Container states within a pod:** Waiting, Running, Terminated.

**Volume in a pod:** Exists as long as the pod with that specific UID exists. For persistent shared storage beyond the pod, use **Persistent Volumes**.

#### 2. Service

- An **abstraction that defines a logical set of pods** and a policy/endpoint for accessing them.
- Problem it solves: Pods are created and destroyed constantly, with changing IP addresses. It's impossible for a frontend to track which pod IPs to connect to.
- Solution: A Service has a **stable Virtual IP address**. Other services communicate with it via this VIP. The Service internally tracks the ever-changing pod IPs and DNS names, mapping them to its VIP.
- A Kubernetes Service is a **logical collection of pods in a cluster**.
- This is where **load balancing** is configured for pods.
- Services expose pods to traffic from inside or outside the cluster.

#### 3. Volume

- An **abstraction for data persistence**.
- Containers are ephemeral â€” data is deleted when a container is deleted.
- Volumes decouple storage from container lifecycle.
- Can be **local storage, public cloud storage, or network storage**.

#### 4. Namespace

- A **segment of the cluster dedicated to a certain purpose** (project, team, environment).
- Used to create multiple **virtual Kubernetes clusters** within a single physical cluster.
- Typically used for environment separation: dev, staging, production.

### 7.6.2 Kubernetes Architecture

**Worker Node Components:**

|Component|Role|
|---|---|
|**Kubelet**|Agent on each worker node. Gets pod configuration from the API server. Ensures specified containers are running and healthy.|
|**Kube-proxy**|Network proxy and load balancer on each worker node. Handles TCP/UDP routing for services.|
|**Container runtime**|The software that actually runs containers (e.g., Docker, containerd).|

**Control Plane (Master) Components** (implied from the content):

- **API Server** â€” the front-end for the Kubernetes control plane; kubelet gets configuration from here.
- **Scheduler** â€” decides which node a pod runs on.
- **Controller Manager** â€” runs controllers that handle node failures, replication, etc.
- **etcd** â€” key-value store that holds the entire cluster state.

---

## 7.7 Kubernetes Functioning

The configuration file (YAML manifest) tells Kubernetes:

- Where to find container images.
- How to establish networking.
- Where to store logs.
- Resource requirements and scaling policies.

**Deploying a new container:**

1. The orchestration tool reads the manifest.
2. Automatically schedules the deployment to the cluster.
3. Finds the right host, respecting defined requirements and constraints.
4. Manages the container's lifecycle based on the manifest specifications.

---

## 7.8 Kubernetes Benefits

|Benefit|Description|
|---|---|
|**Horizontal scaling**|Scale up or down from CLI or UI based on load.|
|**Automated rollouts and rollbacks**|Roll out changes in a controlled fashion; automatically roll back if something goes wrong.|
|**Service discovery and load balancing**|Expose containers via DNS or IP; distribute traffic with built-in load balancing.|
|**Storage orchestration**|Automatically mount local, cloud, or network storage.|
|**Secret and configuration management**|Store passwords, tokens, SSH keys securely; deploy and update without rebuilding images.|
|**Self-healing**|Restart failed containers, replace containers on dead nodes, kill unhealthy containers, wait until ready.|
|**Batch execution**|Manage batch and CI workloads; replace failed containers.|
|**Automatic bin packing**|Schedule containers based on resource needs (CPU, memory) and constraints to maximize utilization.|

---

## 7.9 Container Orchestration System Stack

Container Orchestration mediates between **applications/services** and **container runtimes**, handling three layers:

1. **Service Management:** Labels (key-value pairs attached to pods for identification), groups (related functionality), namespaces (virtual sub-clusters), dependencies, load balancing, readiness checks.
    
2. **Scheduling:** Allocation, replication, container resurrection, rescheduling, rolling deployment, upgrades, downgrades.
    
3. **Resource Management:** Memory, CPU, GPU, volumes, ports, IP addresses.
    

---

## ðŸ“ Q&A â€” Container Orchestration & Kubernetes

**Q1. What is container orchestration and why is it needed?**

> Container orchestration is software that automates the deployment, management, scaling, and networking of containers across a cluster. It's needed because manually managing hundreds of containers â€” handling failures, scaling, networking, and configuration across many hosts â€” is impractical. Orchestration automates all of this.

**Q2. What is a Kubernetes Pod and why is it the basic unit rather than a container?**

> A Pod is a group of one or more tightly coupled containers that share the same IP address, storage, and network namespace. It's the basic unit because containers in a pod always run together on the same node and communicate via localhost â€” they form a logical application unit. Using the pod as the unit rather than individual containers makes scheduling and resource allocation simpler and more coherent.

**Q3. Why does Kubernetes use Services instead of directly connecting to Pod IPs?**

> Pod IPs change constantly as pods are created, destroyed, and rescheduled. A Service provides a **stable Virtual IP address** that remains constant. Other services connect to this VIP, and the Service internally handles mapping to the current, ever-changing pod IPs. This solves the service discovery problem.

**Q4. What is the role of the Kubelet?**

> The Kubelet is an agent running on each worker node. It receives pod specifications from the Kubernetes API server and ensures the containers described in those specs are running and healthy. It watches container states and reports back to the control plane.

**Q5. What is the difference between orchestration and scheduling in Kubernetes?**

> **Scheduling** is about efficiently allocating workloads to available resources â€” deciding which node gets which pod based on CPU, memory, and constraints. **Orchestration** is the broader coordination â€” ensuring the right pods are running, handling failures, rolling out updates, managing services and networking â€” like a conductor coordinating an orchestra.

**Q6. What is "self-healing" in Kubernetes?**

> Kubernetes automatically: restarts failed containers, replaces and reschedules containers when their nodes die, kills containers that don't respond to health checks, and only advertises containers to clients once they are ready. This means the cluster continuously drives itself toward the desired state without human intervention.

**Q7. Explain the concept of "immutable infrastructure" in the context of Kubernetes.**

> In Kubernetes, you never SSH into a running pod to make changes. If an update is needed, you update the container image and deploy a new pod â€” the old one is replaced. Containers are immutable once running. This ensures all instances are identical, prevents configuration drift, and makes rollbacks simple (just deploy the previous image).

**Q8. What is "automatic bin packing" in Kubernetes?**

> Kubernetes automatically schedules containers across cluster nodes based on their resource requirements (CPU, memory) and other constraints (e.g., "must run on a node with a GPU"). It packs containers efficiently to maximize hardware utilization â€” like fitting items into boxes optimally â€” without you having to manually decide which container goes on which server.

**Q9. What is the difference between a Kubernetes Volume and a Persistent Volume?**

> A regular **Volume** exists as long as the Pod that uses it. When the Pod is deleted, the volume is gone. A **Persistent Volume** lives independently of any pod's lifecycle â€” data survives pod restarts, deletions, and reschedulings. PVs are used for databases and any state that must outlive individual pods.

**Q10. Name the three worker node components and their roles.**

> 1. **Kubelet** â€” ensures containers in pods are running per spec from the API server.
> 2. **Kube-proxy** â€” network proxy and load balancer for services; handles TCP/UDP routing.
> 3. **Container runtime** â€” the actual software (e.g., Docker, containerd) that runs containers.

**Q11. What is Docker Swarm and how does it differ from Kubernetes?**

> Docker Swarm provides native clustering for Docker containers, combining multiple Docker engines into a single virtual Docker engine. It's simpler to set up and operates within the Docker ecosystem. Kubernetes is more feature-rich, more complex, battle-tested at massive scale, and has become the industry standard for production container orchestration.

---

# ðŸ” MASTER REVIEW â€” Cross-Topic Questions

These questions integrate multiple topics from across all sections.

**Q1. Trace the journey of an application from developer's laptop to production in a DevOps pipeline, naming the technologies involved at each step.**

> Developer writes code â†’ pushes to **Git** (CI trigger) â†’ **Jenkins** builds the app and runs tests (CI) â†’ app is packaged into a **Docker image** with all dependencies using a **Dockerfile** â†’ image pushed to **Docker Hub/registry** â†’ **Kubernetes** pulls the image and deploys it to a cluster â†’ pods run on worker nodes with **kubelet** managing them â†’ **Services** expose pods to traffic with load balancing â†’ **cgroups** enforce resource limits, **namespaces** provide isolation, **UnionFS** layers the filesystem.

**Q2. How do namespaces and cgroups complement each other in containerization?**

> **Namespaces** handle _what a container can see_ â€” they isolate the container's view of the system (processes, filesystem, network, users). **cgroups** handle _how much a container can use_ â€” they limit and monitor resource consumption (CPU, memory, I/O). Namespaces provide logical isolation; cgroups provide resource governance. Together, they create fully isolated, resource-bounded containers.

**Q3. Why does Docker use UnionFS instead of copying a full filesystem for each container?**

> Copying a full filesystem for every container would be extremely slow and storage-intensive. UnionFS's layered, copy-on-write model means all containers sharing the same base image **reuse the same read-only layers**. Only the thin, writable container layer is unique per container. This makes container creation near-instantaneous and storage efficient.

**Q4. In Kubernetes, a pod keeps crashing. Walk through how Kubernetes handles this.**

> The **kubelet** on the worker node detects the container failure by monitoring the container state. It applies the pod's **restart policy** (usually `Always`) and restarts the failed container. If the pod keeps crashing, Kubernetes applies **exponential backoff** delays between restarts (CrashLoopBackOff). If the node itself fails, the **scheduler** finds a healthy node and the **controller manager** reschedules the pod there. Throughout, the **Service** continues routing traffic to other healthy pod instances, maintaining availability.

**Q5. Why is "it works on my machine" a problem that both Docker and DevOps address?**

> "Works on my machine" happens because developer environments differ from production â€” different OS versions, libraries, configs. **Docker** solves this by packaging the application _with its entire environment_ into a container image. The container runs identically everywhere Docker runs. **DevOps** addresses it by automating deployment to production-like staging environments in the CI/CD pipeline, catching environment-specific failures before production.

---

_End of Cloud Computing Study Notebook_ _Topics covered: Containers, LXC, Docker Architecture, Images, Containers, Registries, PID/UTS/MNT/NET/IPC/USR Namespaces, chroot/pivot_root, cgroups, UnionFS/CoW/Layers, DevOps, CI/CD, Jenkins, Container Orchestration, Kubernetes (Pods, Services, Volumes, Namespaces, Architecture, Benefits)_